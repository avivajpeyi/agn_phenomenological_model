{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/avi.vajpeyi/projects/agn_phenomenological_model/population_inference/agn_outdir/agn_config_complete.ini', '--prior', '/home/avi.vajpeyi/projects/agn_phenomenological_model/population_inference/priors/mass_c_iid_mag_agn_tilt_powerlaw_redshift.prior', '--label', 'agn_mass_c_iid_mag_agn_tilt_powerlaw_redshift', '--models', 'SmoothedMassDistribution', '--models', 'iid_spin_magnitude', '--models', 'agn_spin_orientation', '--models', 'gwpopulation.models.redshift.PowerLawRedshift', '--vt-models', 'SmoothedMassDistribution', '--vt-models', 'gwpopulation.models.redshift.PowerLawRedshift']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:06 bilby INFO    : Loaded 74 posteriors\n",
      "19:06 bilby INFO    : Using SmoothedMassDistribution.\n",
      "19:06 bilby INFO    : Using iid_spin_magnitude.\n",
      "19:06 bilby INFO    : Using agn_spin_orientation.\n",
      "19:06 bilby INFO    : Using PowerLawRedshift from gwpopulation.models.redshift.\n",
      "19:06 bilby INFO    : Using SmoothedMassDistribution.\n",
      "19:06 bilby INFO    : Using PowerLawRedshift from gwpopulation.models.redshift.\n",
      "19:06 bilby INFO    : Loading VT data from selection_effects/o1_o2_o3a_vt_data_aligned_low_spin.hdf5.\n",
      "19:06 bilby WARNING : Cannot import cupy, falling back to numpy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperparameterLikelihood(parameters={})\n",
      "{'alpha': Uniform(minimum=-4, maximum=12, name='alpha', latex_label='$\\\\alpha$', unit=None, boundary='reflective'), 'beta': Uniform(minimum=-4, maximum=12, name='beta', latex_label='$\\\\beta_{q}$', unit=None, boundary=None), 'mmax': Uniform(minimum=30, maximum=100, name='mmax', latex_label='$m_{\\\\max}$', unit=None, boundary=None), 'mmin': Uniform(minimum=2, maximum=10, name='mmin', latex_label='$m_{\\\\min}$', unit=None, boundary=None), 'lam': Uniform(minimum=0, maximum=1, name='lambda', latex_label='$\\\\lambda_{m}$', unit=None, boundary=None), 'mpp': Uniform(minimum=20, maximum=50, name='mpp', latex_label='$\\\\mu_{m}$', unit=None, boundary=None), 'sigpp': Uniform(minimum=1, maximum=10, name='sigpp', latex_label='$\\\\sigma_{m}$', unit=None, boundary=None), 'delta_m': Uniform(minimum=0, maximum=10, name='delta_m', latex_label='$\\\\delta_{m}$', unit=None, boundary=None), 'amax': DeltaFunction(peak=1.0, name=None, latex_label=None, unit=None), 'alpha_chi': DeltaFunction(peak=1.0, name=None, latex_label=None, unit=None), 'beta_chi': DeltaFunction(peak=0.1, name=None, latex_label=None, unit=None), 'sigma_1': DeltaFunction(peak=1.0, name=None, latex_label=None, unit=None), 'sigma_12': Uniform(minimum=0, maximum=1, name='sigma_12', latex_label='$\\\\sigma_{12}$', unit=None, boundary=None), 'lamb': DeltaFunction(peak=0.0, name=None, latex_label=None, unit=None)}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "from importlib import import_module\n",
    "\n",
    "import deepdish as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bilby import run_sampler\n",
    "from bilby.core.prior import LogUniform, PriorDict\n",
    "from bilby.core.utils import logger\n",
    "from bilby.hyper.model import Model\n",
    "from gwpopulation.conversions import convert_to_beta_parameters\n",
    "from gwpopulation.cupy_utils import to_numpy\n",
    "from gwpopulation.hyperpe import HyperparameterLikelihood, RateLikelihood\n",
    "from gwpopulation.models.mass import (\n",
    "    BrokenPowerLawPeakSmoothedMassDistribution,\n",
    "    BrokenPowerLawSmoothedMassDistribution,\n",
    "    MultiPeakSmoothedMassDistribution,\n",
    "    SmoothedMassDistribution,\n",
    "    two_component_primary_mass_ratio,\n",
    ")\n",
    "from gwpopulation.models.spin import (\n",
    "    iid_spin,\n",
    "    iid_spin_magnitude_beta,\n",
    "    iid_spin_orientation_gaussian_isotropic,\n",
    "    independent_spin_magnitude_beta,\n",
    "    independent_spin_orientation_gaussian_isotropic,\n",
    "    agn_spin,\n",
    ")\n",
    "from scipy.stats import gamma\n",
    "from configargparse import Namespace\n",
    "\n",
    "from gwpopulation_pipe import vt_helper\n",
    "from gwpopulation_pipe.parser import create_parser as create_main_parser\n",
    "from gwpopulation_pipe.utils import prior_conversion\n",
    "\n",
    "\n",
    "def create_parser():\n",
    "    parser = create_main_parser()\n",
    "    parser.add_argument(\"--prior\", help=\"Prior file readable by bilby.\")\n",
    "    parser.add_argument(\n",
    "        \"--sampler_name\",\n",
    "        default=\"dynesty\",\n",
    "        help=\"Sampler to use, allowed options are pymultinest, dynesty, nestle, \"\n",
    "        \"cpnest, emcee.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--models\",\n",
    "        type=str,\n",
    "        action=\"append\",\n",
    "        help=\"Model functions to evaluate, default is \"\n",
    "        \"two component mass and iid spins.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--vt-models\",\n",
    "        type=str,\n",
    "        action=\"append\",\n",
    "        help=\"Model functions to evaluate for selection, default is no model\",\n",
    "    )\n",
    "    parser.add(\n",
    "        \"--sampler-kwargs\",\n",
    "        type=str,\n",
    "        default=\"Default\",\n",
    "        help=(\n",
    "            \"Dictionary of sampler-kwargs to pass in, e.g., {nlive: 1000} OR \"\n",
    "            \"pass pre-defined set of sampler-kwargs {Default, FastTest}\"\n",
    "        ),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max-samples\",\n",
    "        default=1e10,\n",
    "        type=int,\n",
    "        help=\"Maximum number of posterior samples per event\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--rate\", default=False, type=bool, help=\"Whether to sample in the merger rate.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max-redshift\", default=2.3, type=float, help=\"Maximum redshift in model.\"\n",
    "    )\n",
    "    return parser\n",
    "\n",
    "\n",
    "def load_prior(args):\n",
    "    hyper_prior = PriorDict(filename=args.prior)\n",
    "    hyper_prior.conversion_function = prior_conversion\n",
    "    if args.rate:\n",
    "        hyper_prior[\"rate\"] = LogUniform(\n",
    "            minimum=1e-1,\n",
    "            maximum=1e3,\n",
    "            name=\"rate\",\n",
    "            latex_label=\"$R$\",\n",
    "            boundary=\"reflective\",\n",
    "        )\n",
    "    return hyper_prior\n",
    "\n",
    "\n",
    "MODEL_MAP = {\n",
    "    \"two_component_primary_mass_ratio\": two_component_primary_mass_ratio,\n",
    "    \"iid_spin\": iid_spin,\n",
    "    \"iid_spin_magnitude\": iid_spin_magnitude_beta,\n",
    "    \"ind_spin_magnitude\": independent_spin_magnitude_beta,\n",
    "    \"iid_spin_orientation\": iid_spin_orientation_gaussian_isotropic,\n",
    "    \"two_comp_iid_spin_orientation\": iid_spin_orientation_gaussian_isotropic,\n",
    "    \"ind_spin_orientation\": independent_spin_orientation_gaussian_isotropic,\n",
    "    \"agn_spin_orientation\": agn_spin,\n",
    "    \"SmoothedMassDistribution\": SmoothedMassDistribution,\n",
    "    \"BrokenPowerLawSmoothedMassDistribution\": BrokenPowerLawSmoothedMassDistribution,\n",
    "    \"MultiPeakSmoothedMassDistribution\": MultiPeakSmoothedMassDistribution,\n",
    "    \"BrokenPowerLawPeakSmoothedMassDistribution\": BrokenPowerLawPeakSmoothedMassDistribution,\n",
    "}\n",
    "\n",
    "\n",
    "def load_model(args):\n",
    "    if args.models is None:\n",
    "        args.models = [\n",
    "            \"two_component_primary_mass_ratio\",\n",
    "            \"iid_spin\",\n",
    "            \"gwpopulation.models.redshift.PowerLawRedshift\",\n",
    "        ]\n",
    "    logger.info(f\"Loading models = {args.models}\")\n",
    "    model = Model([_load_model(model, args) for model in args.models])\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_vt(args):\n",
    "    if args.vt_function == \"\" or args.vt_file == \"None\":\n",
    "        return vt_helper.dummy_selection\n",
    "    vt_model = Model([_load_model(model, args) for model in args.vt_models])\n",
    "    try:\n",
    "        vt_func = getattr(vt_helper, args.vt_function)\n",
    "        return vt_func(args.vt_file, model=vt_model)\n",
    "    except AttributeError:\n",
    "        return vt_helper.injection_resampling_vt(vt_file=args.vt_file, model=vt_model)\n",
    "\n",
    "\n",
    "def _load_model(model, args):\n",
    "    if \".\" in model:\n",
    "        split_model = model.split(\".\")\n",
    "        module = \".\".join(split_model[:-1])\n",
    "        function = split_model[-1]\n",
    "        _model = getattr(import_module(module), function)\n",
    "        logger.info(f\"Using {function} from {module}.\")\n",
    "    elif model in MODEL_MAP:\n",
    "        _model = MODEL_MAP[model]\n",
    "        logger.info(f\"Using {model}.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model} not found.\")\n",
    "    if inspect.isclass(_model):\n",
    "        if \"redshift\" in model.lower():\n",
    "            kwargs = dict(z_max=args.max_redshift)\n",
    "        else:\n",
    "            kwargs = dict()\n",
    "        _model = _model(**kwargs)\n",
    "    return _model\n",
    "\n",
    "\n",
    "def create_likelihood(args, posteriors, model, selection):\n",
    "    if args.rate:\n",
    "        likelihood_class = RateLikelihood\n",
    "    else:\n",
    "        likelihood_class = HyperparameterLikelihood\n",
    "    likelihood = likelihood_class(\n",
    "        posteriors,\n",
    "        model,\n",
    "        conversion_function=convert_to_beta_parameters,\n",
    "        selection_function=selection,\n",
    "        max_samples=args.max_samples,\n",
    "    )\n",
    "\n",
    "    return likelihood\n",
    "\n",
    "\n",
    "def get_sampler_kwargs(args):\n",
    "    if args.sampler_kwargs == \"Default\":\n",
    "        sampler_kwargs = dict()\n",
    "    elif not isinstance(args.sampler_kwargs, dict):\n",
    "        sampler_kwargs = dict()\n",
    "        for arg in args.sampler_kwargs:\n",
    "            key = arg.split(\":\")[0].strip()\n",
    "            value = arg.split(\":\")[1].strip()\n",
    "            try:\n",
    "                value = eval(value)\n",
    "            except NameError:\n",
    "                pass\n",
    "            sampler_kwargs[key] = value\n",
    "    else:\n",
    "        sampler_kwargs = args.sampler_args\n",
    "    if args.sampler_name == \"cpnest\" and \"seed\" not in sampler_kwargs:\n",
    "        sampler_kwargs[\"seed\"] = np.random.randint(0, 1e6)\n",
    "    sampler_kwargs[\"nlive\"] = 500\n",
    "    sampler_kwargs[\"nact\"] = 2\n",
    "    sampler_kwargs[\"walks\"] = 5\n",
    "    return sampler_kwargs\n",
    "\n",
    "\n",
    "\n",
    "def get_likelihood_and_hyoperprior_from_args(cli_str):\n",
    "    parser = create_parser()\n",
    "    cli_args = cli_str.split(\" \")[1:]\n",
    "    print(cli_args)\n",
    "    args, unknown_args = parser.parse_known_args(cli_args)\n",
    "    posterior_file = os.path.join(args.run_dir, \"data\", f\"{args.data_label}.pkl\")\n",
    "    posteriors = pd.read_pickle(posterior_file)\n",
    "    for ii, post in enumerate(posteriors):\n",
    "        posteriors[ii] = post[post[\"redshift\"] < args.max_redshift]\n",
    "    vt_helper.N_EVENTS = len(posteriors)\n",
    "    vt_helper.max_redshift = args.max_redshift\n",
    "    logger.info(f\"Loaded {len(posteriors)} posteriors\")\n",
    "    event_ids = list()\n",
    "    with open(\n",
    "        os.path.join(args.run_dir, \"data\", f\"{args.data_label}_posterior_files.txt\"),\n",
    "        \"r\",\n",
    "    ) as ff:\n",
    "        for line in ff.readlines():\n",
    "            event_ids.append(line.split(\":\")[0])\n",
    "\n",
    "    hyper_prior = load_prior(args)\n",
    "    model = load_model(args)\n",
    "    selection = load_vt(args)\n",
    "\n",
    "    likelihood = create_likelihood(args, posteriors, model, selection)\n",
    "    print(likelihood)\n",
    "    print(hyper_prior)\n",
    "    return likelihood, hyper_prior\n",
    "\n",
    "likelihood, hyperprior = get_likelihood_and_hyoperprior_from_args(\"gwpopulation_pipe_analysis /home/avi.vajpeyi/projects/agn_phenomenological_model/population_inference/agn_outdir/agn_config_complete.ini --prior /home/avi.vajpeyi/projects/agn_phenomenological_model/population_inference/priors/mass_c_iid_mag_agn_tilt_powerlaw_redshift.prior --label agn_mass_c_iid_mag_agn_tilt_powerlaw_redshift --models SmoothedMassDistribution --models iid_spin_magnitude --models agn_spin_orientation --models gwpopulation.models.redshift.PowerLawRedshift --vt-models SmoothedMassDistribution --vt-models gwpopulation.models.redshift.PowerLawRedshift\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avi.vajpeyi/projects/gwpopulation/gwpopulation/models/mass.py:462: RuntimeWarning: overflow encountered in exp\n",
      "  window[smoothing_region] = 1 / (xp.exp(exponent) + 1)\n",
      "/home/avi.vajpeyi/projects/gwpopulation/gwpopulation/models/mass.py:398: RuntimeWarning: invalid value encountered in true_divide\n",
      "  p_q /= self.norm_p_q(beta=beta, mmin=mmin, delta_m=delta_m)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 5.388428170693551,\n",
      " 'alpha_chi': 1.0,\n",
      " 'amax': 1.0,\n",
      " 'amax_1': 1,\n",
      " 'amax_2': 1,\n",
      " 'beta': -2.799799686537705,\n",
      " 'beta_chi': 0.1,\n",
      " 'delta_m': 4.625771139312324,\n",
      " 'lam': 0.9956025878656064,\n",
      " 'lamb': 0.0,\n",
      " 'ln_likelihood': nan,\n",
      " 'ln_prior': 3529.139443186719,\n",
      " 'mmax': 39.70552752015852,\n",
      " 'mmin': 7.936809075332267,\n",
      " 'mpp': 45.230052415351764,\n",
      " 'sigma_1': 1.0,\n",
      " 'sigma_12': 0.22164976385620705,\n",
      " 'sigpp': 1.3074265386272172}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avi.vajpeyi/projects/gwpopulation/gwpopulation/hyperpe.py:149: RuntimeWarning: divide by zero encountered in log\n",
      "  xp.sum(self.hyper_prior.prob(self.data) / self.sampling_prior, axis=-1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "def test_likelihood(likelihood, hyper_prior):\n",
    "    theta = hyper_prior.sample()\n",
    "    likelihood.parameters.update(theta)\n",
    "    ln_l = likelihood.log_likelihood()\n",
    "    params = params = {\n",
    "    key: t for key, t in zip(hyper_prior.keys(), theta.values())}\n",
    "    ln_p = hyper_prior.ln_prob(params)\n",
    "    pprint(dict(ln_likelihood=ln_l, ln_prior=ln_p, **theta))\n",
    "    \n",
    "\n",
    "test_likelihood(likelihood, hyperprior)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gwpop",
   "language": "python",
   "name": "gwpop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
